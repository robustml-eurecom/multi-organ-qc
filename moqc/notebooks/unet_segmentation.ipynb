{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.transforms.compose import Compose\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    LoadImaged,\n",
    "    RandRotate90d,\n",
    "    Resized,\n",
    "    ScaleIntensityd,\n",
    "    SqueezeDimd,\n",
    "    ResizeWithPadOrCropd,\n",
    "    CenterSpatialCropd,\n",
    ")\n",
    "\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.data import DataLoader, PatchDataset, create_test_image_3d\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "plt.rcParams[\"figure.figsize\"] = 12, 8\n",
    "monai.utils.set_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"MSD_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityd(keys=\"image\"),\n",
    "        RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# available options are: ['Task01_BrainTumour', 'Task02_Heart', \n",
    "# 'Task03_Liver', 'Task04_Hippocampus', 'Task05_Prostate', 'Task06_Lung', \n",
    "# 'Task07_Pancreas', 'Task08_HepaticVessel', 'Task09_Spleen', 'Task10_Colon']\n",
    "volume_ds = DecathlonDataset(\n",
    "    root_dir=root_dir, task=\"Task04_Hippocampus\", transform=transforms, section=\"training\", seed=12345, download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_loader = DataLoader(volume_ds, batch_size=1, pin_memory=torch.cuda.is_available(), num_workers=8)\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(\"first volume's shape: \", check_data[\"image\"].shape, check_data[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(check_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 4\n",
    "patch_func = monai.transforms.RandSpatialCropSamplesd(\n",
    "    keys=[\"image\", \"label\"],\n",
    "    roi_size=[-1, -1, 1],  # dynamic spatial_size for the first two dimensions\n",
    "    num_samples=num_samples,\n",
    "    random_size=False,\n",
    ")\n",
    "\n",
    "patch_transform = Compose(\n",
    "    [\n",
    "        SqueezeDimd(keys=[\"image\", \"label\"], dim=-1),  # squeeze the last dim\n",
    "        Resized(keys=[\"image\", \"label\"], spatial_size=[256, 256]),\n",
    "        # to use crop/pad instead of resize:\n",
    "        #ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=[256, 256], mode=\"replicate\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "patch_ds = PatchDataset(\n",
    "    volume_ds,\n",
    "    transform=patch_transform,\n",
    "    patch_func=patch_func,\n",
    "    samples_per_image=num_samples,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    patch_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,  # this shuffles slices from different volumes\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "check_data = monai.utils.misc.first(train_loader)\n",
    "print(\"first patch's shape: \", check_data[\"image\"].shape, check_data[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_loader): \n",
    "    if len(np.unique(batch[\"label\"])) > 2: \n",
    "        print(\"more than 2 classes in the label\", np.unique(batch[\"label\"]), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(check_data[\"label\"][6].squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=2,\n",
    "    out_channels=3,\n",
    "    channels=(32, 32, 64, 64, 128, 128, 512),\n",
    "    strides=(2, 1, 2, 1, 2, 1)\n",
    ").to(device)\n",
    "\n",
    "swin_net = monai.networks.nets.SwinUNETR(\n",
    "    img_size=(256,256), \n",
    "    in_channels=1, \n",
    "    out_channels=3, \n",
    "    use_checkpoint=True, \n",
    "    spatial_dims=2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_DC = monai.losses.DiceLoss(softmax=True)\n",
    "optimizer = torch.optim.Adam(unet.parameters(), 1e-4, weight_decay=1e-5)\n",
    "\n",
    "epoch_loss_values = []\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{num_epochs}\")\n",
    "    unet.train()\n",
    "    epoch_loss, step = 0, 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[\"image\"].to(device), np.round(batch_data[\"label\"].cpu().numpy())\n",
    "        optimizer.zero_grad()\n",
    "        labels = F.one_hot(torch.tensor(labels).to(device).long(), num_classes=3).squeeze().transpose(1, 3)\n",
    "        outputs = swin_net(inputs).to(device)\n",
    "        loss = loss_DC(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(patch_ds) // train_loader.batch_size\n",
    "        if step % 25 == 0:\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "print(\"train completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "from monai.visualize import matshow3d\n",
    "from monai.inferers import SliceInferer\n",
    "\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_ds = DecathlonDataset(\n",
    "    root_dir=root_dir, task=\"Task09_Spleen\", transform=val_transforms, section=\"validation\", seed=12345, download=False\n",
    ")\n",
    "\n",
    "data_loader = DataLoader(val_ds, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "unet.eval()\n",
    "with torch.no_grad():\n",
    "    for val_data in data_loader:\n",
    "        val_images = val_data[\"image\"].to(device)\n",
    "        roi_size = (256, 256)\n",
    "        sw_batch_size = 8\n",
    "        slice_inferer = SliceInferer(\n",
    "            roi_size=roi_size,\n",
    "            sw_batch_size=sw_batch_size,\n",
    "            spatial_dim=1,  # Spatial dim to slice along is defined here\n",
    "            device=torch.device(\"cpu\"),\n",
    "            padding_mode=\"replicate\",\n",
    "        )\n",
    "        val_output = slice_inferer(val_images, unet).cpu()\n",
    "        dice_metric(y_pred=val_output > 0.5, y=val_data[\"label\"])\n",
    "        print(\"Dice: \", dice_metric.get_buffer()[-1][0])\n",
    "        #fig = plt.figure(figsize=(10, 4))\n",
    "        #plt.subplot(1, 2, 1)\n",
    "        #matshow3d(val_output[0].squeeze(), fig=plt.gca())\n",
    "        #plt.subplot(1, 2, 2)\n",
    "        #matshow3d(val_images[0].squeeze(), fig=plt.gca())\n",
    "        #plt.show()\n",
    "    print(f\"Avg Dice: {dice_metric.aggregate().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_output[0].squeeze().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_data['label'][0].squeeze()[:,:,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = val_output[0].squeeze().permute(2, 0, 1).to('cpu').detach().numpy()\n",
    "volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = volume[0].shape\n",
    "\n",
    "# Define frames\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import plotly.graph_objects as go\n",
    "nb_frames = volume.shape[0]\n",
    "\n",
    "fig = go.Figure(frames=[go.Frame(data=go.Surface(\n",
    "    z=(nb_frames*.1 - k * 0.1) * np.ones((r, c)),\n",
    "    surfacecolor=np.flipud(volume[(nb_frames-1) - k]),\n",
    "    cmin=0, cmax=200\n",
    "    ),\n",
    "    name=str(k) # you need to name the frame for the animation to behave properly\n",
    "    )\n",
    "    for k in range(nb_frames)])\n",
    "\n",
    "# Add data to be displayed before animation starts\n",
    "fig.add_trace(go.Surface(\n",
    "    z=nb_frames*.1 * np.ones((r, c)),\n",
    "    surfacecolor=np.flipud(volume[(nb_frames-1)]),\n",
    "    colorscale='Gray',\n",
    "    cmin=0, cmax=200,\n",
    "    colorbar=dict(thickness=20, ticklen=4)\n",
    "    ))\n",
    "\n",
    "\n",
    "def frame_args(duration):\n",
    "    return {\n",
    "            \"frame\": {\"duration\": duration},\n",
    "            \"mode\": \"immediate\",\n",
    "            \"fromcurrent\": True,\n",
    "            \"transition\": {\"duration\": duration, \"easing\": \"linear\"},\n",
    "        }\n",
    "\n",
    "sliders = [\n",
    "            {\n",
    "                \"pad\": {\"b\": 10, \"t\": 60},\n",
    "                \"len\": 0.9,\n",
    "                \"x\": 0.1,\n",
    "                \"y\": 0,\n",
    "                \"steps\": [\n",
    "                    {\n",
    "                        \"args\": [[f.name], frame_args(0)],\n",
    "                        \"label\": str(k),\n",
    "                        \"method\": \"animate\",\n",
    "                    }\n",
    "                    for k, f in enumerate(fig.frames)\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "         title='Slices in volumetric data',\n",
    "         width=600,\n",
    "         height=600,\n",
    "         scene=dict(\n",
    "                    zaxis=dict(range=[-0.1, nb_frames*.1], autorange=False),\n",
    "                    aspectratio=dict(x=1, y=1, z=1),\n",
    "                    ),\n",
    "         updatemenus = [\n",
    "            {\n",
    "                \"buttons\": [\n",
    "                    {\n",
    "                        \"args\": [None, frame_args(100)],\n",
    "                        \"label\": \"&#9654;\", # play symbol\n",
    "                        \"method\": \"animate\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"args\": [[None], frame_args(0)],\n",
    "                        \"label\": \"&#9724;\", # pause symbol\n",
    "                        \"method\": \"animate\",\n",
    "                    },\n",
    "                ],\n",
    "                \"direction\": \"left\",\n",
    "                \"pad\": {\"r\": 10, \"t\": 70},\n",
    "                \"type\": \"buttons\",\n",
    "                \"x\": 0.1,\n",
    "                \"y\": 0,\n",
    "            }\n",
    "         ],\n",
    "         sliders=sliders\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_2d_slices_from(data):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        image = data[i]['image']\n",
    "        label = data[i]['label']\n",
    "        try:\n",
    "            images = torch.cat((images, torch.Tensor(image).unsqueeze(dim=0))) if len(images) else torch.Tensor(image).unsqueeze(dim=0)\n",
    "            labels = torch.cat((labels, torch.Tensor(label))) if len(labels) else torch.Tensor(label)\n",
    "        except: print(\"Different dimensions: \", image.size(), label.size(), \". Skipping image.\")\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio\n",
    "import os\n",
    "\n",
    "def save_for_ae(loader, model, threshold, dir):\n",
    "    count = 0\n",
    "    seg_path, gt_path = os.path.join(dir, 'measures/segmentations'), os.path.join(dir, 'labels')\n",
    "    if not os.path.exists(os.path.join(dir, 'measures')):  os.makedirs(seg_path)\n",
    "    if not os.path.exists(os.path.join(dir, 'labels')): os.makedirs(gt_path) \n",
    "    for i, batch in enumerate(loader):\n",
    "        w, h = batch['label'][0].size()[0], batch['label'][0].size()[1]\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output_image = model(batch[\"image\"].to(device))\n",
    "            output_image = torchio.ScalarImage(tensor=output_image.cpu().numpy())\n",
    "        \n",
    "        # check if  pixels are non zero\n",
    "        if torch.count_nonzero(batch['label'][0]).item() > threshold:\n",
    "            count +=1 \n",
    "            label_image = torchio.ScalarImage(tensor=batch['label'].cpu().numpy())\n",
    "            output_image.save(os.path.join(seg_path, f'patient_{i:03d}.nii.gz'))\n",
    "            label_image.save(os.path.join(gt_path, f'segmentation_{i:03d}.nii.gz'))\n",
    "    print(f\"Successfully saved {count} images to \", dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    patch_ds,\n",
    "    batch_size=1,\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "save_for_ae(loader, unet, .005, 'data/prostate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "img = nib.load('data/spleen/segmentations/segmentation_10.nii.gz').get_fdata()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FORE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
