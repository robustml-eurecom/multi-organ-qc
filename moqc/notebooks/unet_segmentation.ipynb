{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/marciano/experiments/multi-organ-qc/moqc\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/marciano/experiments/multi-organ-qc\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "from monai.transforms.compose import Compose\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    LoadImaged,\n",
    "    RandRotate90d,\n",
    "    Resized,\n",
    "    ScaleIntensityd,\n",
    "    SqueezeDimd,\n",
    "    ResizeWithPadOrCropd,\n",
    "    CenterSpatialCropd,\n",
    ")\n",
    "\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.data import DataLoader, PatchDataset, create_test_image_3d\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "plt.rcParams[\"figure.figsize\"] = 12, 8\n",
    "monai.utils.set_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"MSD_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n",
      "Loading dataset:   0%|          | 0/208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 208/208 [00:00<00:00, 233.45it/s]\n"
     ]
    }
   ],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityd(keys=\"image\"),\n",
    "        RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# available options are: ['Task01_BrainTumour', 'Task02_Heart', \n",
    "# 'Task03_Liver', 'Task04_Hippocampus', 'Task05_Prostate', 'Task06_Lung', \n",
    "# 'Task07_Pancreas', 'Task08_HepaticVessel', 'Task09_Spleen', 'Task10_Colon']\n",
    "volume_ds = DecathlonDataset(\n",
    "    root_dir=root_dir, task=\"Task04_Hippocampus\", transform=transforms, section=\"training\", seed=12345, download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first volume's shape:  torch.Size([1, 1, 40, 48, 34]) torch.Size([1, 1, 40, 48, 34])\n"
     ]
    }
   ],
   "source": [
    "check_loader = DataLoader(volume_ds, batch_size=1, pin_memory=torch.cuda.is_available(), num_workers=8)\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(\"first volume's shape: \", check_data[\"image\"].shape, check_data[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(check_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first patch's shape:  torch.Size([8, 1, 256, 256]) torch.Size([8, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "num_samples = 4\n",
    "patch_func = monai.transforms.RandSpatialCropSamplesd(\n",
    "    keys=[\"image\", \"label\"],\n",
    "    roi_size=[-1, -1, 1],  # dynamic spatial_size for the first two dimensions\n",
    "    num_samples=num_samples,\n",
    "    random_size=False,\n",
    ")\n",
    "\n",
    "patch_transform = Compose(\n",
    "    [\n",
    "        SqueezeDimd(keys=[\"image\", \"label\"], dim=-1),  # squeeze the last dim\n",
    "        Resized(keys=[\"image\", \"label\"], spatial_size=[256, 256]),\n",
    "        # to use crop/pad instead of resize:\n",
    "        #ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=[256, 256], mode=\"replicate\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "patch_ds = PatchDataset(\n",
    "    volume_ds,\n",
    "    transform=patch_transform,\n",
    "    patch_func=patch_func,\n",
    "    samples_per_image=num_samples,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    patch_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,  # this shuffles slices from different volumes\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "check_data = monai.utils.misc.first(train_loader)\n",
    "print(\"first patch's shape: \", check_data[\"image\"].shape, check_data[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 0\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 1\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 2\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 3\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 4\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 5\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 6\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 7\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 8\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 9\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 10\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 11\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 12\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 13\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 14\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 15\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 16\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 17\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 18\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 19\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 20\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 21\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 22\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 23\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 24\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 25\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 26\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 27\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 28\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 29\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 30\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 31\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 32\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 33\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 34\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 35\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 36\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 37\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 38\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 39\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 40\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 41\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 42\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 43\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 44\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 45\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 46\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 47\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 48\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 49\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 50\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 51\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 52\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 53\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 54\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 55\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 56\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 57\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 58\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 59\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 60\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 61\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 62\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 63\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 64\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 65\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 66\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 67\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 68\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 69\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 70\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 71\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 72\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 73\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 74\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 75\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 76\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 77\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 78\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 79\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 80\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 81\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 82\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 83\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 84\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 85\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 86\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 87\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 88\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 89\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 90\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 91\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 92\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 93\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ] 94\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 95\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 96\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 97\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 98\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 99\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 100\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 101\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.5  2.  ] 102\n",
      "more than 2 classes in the label [0.   0.25 0.5  0.75 1.   1.25 1.5  2.  ] 103\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader): \n",
    "    if len(np.unique(batch[\"label\"])) > 2: \n",
    "        print(\"more than 2 classes in the label\", np.unique(batch[\"label\"]), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(check_data[\"label\"][6].squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=2,\n",
    "    out_channels=3,\n",
    "    channels=(32, 32, 64, 64, 128, 128, 512),\n",
    "    strides=(2, 1, 2, 1, 2, 1)\n",
    ").to(device)\n",
    "\n",
    "swin_net = monai.networks.nets.SwinUNETR(\n",
    "    img_size=(256,256), \n",
    "    in_channels=1, \n",
    "    out_channels=3, \n",
    "    use_checkpoint=True, \n",
    "    spatial_dims=2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/100\n",
      "25/104, train_loss: 0.7864\n",
      "50/104, train_loss: 0.8072\n",
      "75/104, train_loss: 0.8008\n",
      "100/104, train_loss: 0.7856\n",
      "epoch 1 average loss: 0.7906\n",
      "----------\n",
      "epoch 2/100\n",
      "25/104, train_loss: 0.7783\n",
      "50/104, train_loss: 0.7930\n",
      "75/104, train_loss: 0.7843\n",
      "100/104, train_loss: 0.7894\n",
      "epoch 2 average loss: 0.7904\n",
      "----------\n",
      "epoch 3/100\n",
      "25/104, train_loss: 0.7978\n",
      "50/104, train_loss: 0.8034\n",
      "75/104, train_loss: 0.8062\n",
      "100/104, train_loss: 0.7866\n",
      "epoch 3 average loss: 0.7906\n",
      "----------\n",
      "epoch 4/100\n",
      "25/104, train_loss: 0.7941\n",
      "50/104, train_loss: 0.8014\n",
      "75/104, train_loss: 0.7935\n",
      "100/104, train_loss: 0.7856\n",
      "epoch 4 average loss: 0.7919\n",
      "----------\n",
      "epoch 5/100\n",
      "25/104, train_loss: 0.7866\n",
      "50/104, train_loss: 0.7904\n",
      "75/104, train_loss: 0.8020\n",
      "100/104, train_loss: 0.7851\n",
      "epoch 5 average loss: 0.7929\n",
      "----------\n",
      "epoch 6/100\n",
      "25/104, train_loss: 0.7790\n",
      "50/104, train_loss: 0.8007\n",
      "75/104, train_loss: 0.7897\n",
      "100/104, train_loss: 0.7843\n",
      "epoch 6 average loss: 0.7915\n",
      "----------\n",
      "epoch 7/100\n",
      "25/104, train_loss: 0.7953\n",
      "50/104, train_loss: 0.7925\n",
      "75/104, train_loss: 0.7824\n",
      "100/104, train_loss: 0.7833\n",
      "epoch 7 average loss: 0.7900\n",
      "----------\n",
      "epoch 8/100\n",
      "25/104, train_loss: 0.7706\n",
      "50/104, train_loss: 0.7999\n",
      "75/104, train_loss: 0.7841\n",
      "100/104, train_loss: 0.7736\n",
      "epoch 8 average loss: 0.7907\n",
      "----------\n",
      "epoch 9/100\n",
      "25/104, train_loss: 0.7916\n",
      "50/104, train_loss: 0.7880\n",
      "75/104, train_loss: 0.7983\n",
      "100/104, train_loss: 0.7874\n",
      "epoch 9 average loss: 0.7915\n",
      "----------\n",
      "epoch 10/100\n",
      "25/104, train_loss: 0.7923\n",
      "50/104, train_loss: 0.7994\n",
      "75/104, train_loss: 0.8027\n",
      "100/104, train_loss: 0.7833\n",
      "epoch 10 average loss: 0.7911\n",
      "----------\n",
      "epoch 11/100\n",
      "25/104, train_loss: 0.8010\n",
      "50/104, train_loss: 0.7899\n",
      "75/104, train_loss: 0.7961\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/marciano/experiments/multi-organ-qc/moqc/notebooks/unet_segmentation.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmagnolia/data/marciano/experiments/multi-organ-qc/moqc/notebooks/unet_segmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmagnolia/data/marciano/experiments/multi-organ-qc/moqc/notebooks/unet_segmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m labels \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(torch\u001b[39m.\u001b[39mtensor(labels)\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mlong(), num_classes\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmagnolia/data/marciano/experiments/multi-organ-qc/moqc/notebooks/unet_segmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m outputs \u001b[39m=\u001b[39m swin_net(inputs)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmagnolia/data/marciano/experiments/multi-organ-qc/moqc/notebooks/unet_segmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_DC(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmagnolia/data/marciano/experiments/multi-organ-qc/moqc/notebooks/unet_segmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/data/marciano/my_envs/FORE/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/marciano/my_envs/FORE/lib/python3.8/site-packages/monai/networks/nets/swin_unetr.py:301\u001b[0m, in \u001b[0;36mSwinUNETR.forward\u001b[0;34m(self, x_in)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x_in):\n\u001b[0;32m--> 301\u001b[0m     hidden_states_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mswinViT(x_in, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize)\n\u001b[1;32m    302\u001b[0m     enc0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder1(x_in)\n\u001b[1;32m    303\u001b[0m     enc1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder2(hidden_states_out[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/data/marciano/my_envs/FORE/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/marciano/my_envs/FORE/lib/python3.8/site-packages/monai/networks/nets/swin_unetr.py:1038\u001b[0m, in \u001b[0;36mSwinTransformer.forward\u001b[0;34m(self, x, normalize)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m-> 1038\u001b[0m     x0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpatch_embed(x)\n\u001b[1;32m   1039\u001b[0m     x0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_drop(x0)\n\u001b[1;32m   1040\u001b[0m     x0_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_out(x0, normalize)\n",
      "File \u001b[0;32m/data/marciano/my_envs/FORE/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/marciano/my_envs/FORE/lib/python3.8/site-packages/monai/networks/blocks/patchembedding.py:174\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 174\u001b[0m     x_shape \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49msize()\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x_shape) \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[1;32m    176\u001b[0m         _, _, d, h, w \u001b[39m=\u001b[39m x_shape\n",
      "File \u001b[0;32m/data/marciano/my_envs/FORE/lib/python3.8/site-packages/monai/data/meta_tensor.py:276\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 276\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m__torch_function__(func, types, args, kwargs)\n\u001b[1;32m    277\u001b[0m \u001b[39m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39m#     return ret\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[0;32m/data/marciano/my_envs/FORE/lib/python3.8/site-packages/torch/_tensor.py:1296\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[39mwith\u001b[39;00m _C\u001b[39m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m   1295\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1296\u001b[0m     \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1297\u001b[0m         \u001b[39mreturn\u001b[39;00m ret\n\u001b[1;32m   1298\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_DC = monai.losses.DiceLoss(softmax=True)\n",
    "optimizer = torch.optim.Adam(unet.parameters(), 1e-4, weight_decay=1e-5)\n",
    "\n",
    "epoch_loss_values = []\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{num_epochs}\")\n",
    "    unet.train()\n",
    "    epoch_loss, step = 0, 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[\"image\"].to(device), np.round(batch_data[\"label\"].cpu().numpy())\n",
    "        optimizer.zero_grad()\n",
    "        labels = F.one_hot(torch.tensor(labels).to(device).long(), num_classes=3).squeeze().transpose(1, 3)\n",
    "        outputs = swin_net(inputs).to(device)\n",
    "        loss = loss_DC(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(patch_ds) // train_loader.batch_size\n",
    "        if step % 25 == 0:\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "print(\"train completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "from monai.visualize import matshow3d\n",
    "from monai.inferers import SliceInferer\n",
    "\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_ds = DecathlonDataset(\n",
    "    root_dir=root_dir, task=\"Task09_Spleen\", transform=val_transforms, section=\"validation\", seed=12345, download=False\n",
    ")\n",
    "\n",
    "data_loader = DataLoader(val_ds, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "unet.eval()\n",
    "with torch.no_grad():\n",
    "    for val_data in data_loader:\n",
    "        val_images = val_data[\"image\"].to(device)\n",
    "        roi_size = (256, 256)\n",
    "        sw_batch_size = 8\n",
    "        slice_inferer = SliceInferer(\n",
    "            roi_size=roi_size,\n",
    "            sw_batch_size=sw_batch_size,\n",
    "            spatial_dim=1,  # Spatial dim to slice along is defined here\n",
    "            device=torch.device(\"cpu\"),\n",
    "            padding_mode=\"replicate\",\n",
    "        )\n",
    "        val_output = slice_inferer(val_images, unet).cpu()\n",
    "        dice_metric(y_pred=val_output > 0.5, y=val_data[\"label\"])\n",
    "        print(\"Dice: \", dice_metric.get_buffer()[-1][0])\n",
    "        #fig = plt.figure(figsize=(10, 4))\n",
    "        #plt.subplot(1, 2, 1)\n",
    "        #matshow3d(val_output[0].squeeze(), fig=plt.gca())\n",
    "        #plt.subplot(1, 2, 2)\n",
    "        #matshow3d(val_images[0].squeeze(), fig=plt.gca())\n",
    "        #plt.show()\n",
    "    print(f\"Avg Dice: {dice_metric.aggregate().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_output[0].squeeze().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_data['label'][0].squeeze()[:,:,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = val_output[0].squeeze().permute(2, 0, 1).to('cpu').detach().numpy()\n",
    "volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = volume[0].shape\n",
    "\n",
    "# Define frames\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import plotly.graph_objects as go\n",
    "nb_frames = volume.shape[0]\n",
    "\n",
    "fig = go.Figure(frames=[go.Frame(data=go.Surface(\n",
    "    z=(nb_frames*.1 - k * 0.1) * np.ones((r, c)),\n",
    "    surfacecolor=np.flipud(volume[(nb_frames-1) - k]),\n",
    "    cmin=0, cmax=200\n",
    "    ),\n",
    "    name=str(k) # you need to name the frame for the animation to behave properly\n",
    "    )\n",
    "    for k in range(nb_frames)])\n",
    "\n",
    "# Add data to be displayed before animation starts\n",
    "fig.add_trace(go.Surface(\n",
    "    z=nb_frames*.1 * np.ones((r, c)),\n",
    "    surfacecolor=np.flipud(volume[(nb_frames-1)]),\n",
    "    colorscale='Gray',\n",
    "    cmin=0, cmax=200,\n",
    "    colorbar=dict(thickness=20, ticklen=4)\n",
    "    ))\n",
    "\n",
    "\n",
    "def frame_args(duration):\n",
    "    return {\n",
    "            \"frame\": {\"duration\": duration},\n",
    "            \"mode\": \"immediate\",\n",
    "            \"fromcurrent\": True,\n",
    "            \"transition\": {\"duration\": duration, \"easing\": \"linear\"},\n",
    "        }\n",
    "\n",
    "sliders = [\n",
    "            {\n",
    "                \"pad\": {\"b\": 10, \"t\": 60},\n",
    "                \"len\": 0.9,\n",
    "                \"x\": 0.1,\n",
    "                \"y\": 0,\n",
    "                \"steps\": [\n",
    "                    {\n",
    "                        \"args\": [[f.name], frame_args(0)],\n",
    "                        \"label\": str(k),\n",
    "                        \"method\": \"animate\",\n",
    "                    }\n",
    "                    for k, f in enumerate(fig.frames)\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "         title='Slices in volumetric data',\n",
    "         width=600,\n",
    "         height=600,\n",
    "         scene=dict(\n",
    "                    zaxis=dict(range=[-0.1, nb_frames*.1], autorange=False),\n",
    "                    aspectratio=dict(x=1, y=1, z=1),\n",
    "                    ),\n",
    "         updatemenus = [\n",
    "            {\n",
    "                \"buttons\": [\n",
    "                    {\n",
    "                        \"args\": [None, frame_args(100)],\n",
    "                        \"label\": \"&#9654;\", # play symbol\n",
    "                        \"method\": \"animate\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"args\": [[None], frame_args(0)],\n",
    "                        \"label\": \"&#9724;\", # pause symbol\n",
    "                        \"method\": \"animate\",\n",
    "                    },\n",
    "                ],\n",
    "                \"direction\": \"left\",\n",
    "                \"pad\": {\"r\": 10, \"t\": 70},\n",
    "                \"type\": \"buttons\",\n",
    "                \"x\": 0.1,\n",
    "                \"y\": 0,\n",
    "            }\n",
    "         ],\n",
    "         sliders=sliders\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_2d_slices_from(data):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        image = data[i]['image']\n",
    "        label = data[i]['label']\n",
    "        try:\n",
    "            images = torch.cat((images, torch.Tensor(image).unsqueeze(dim=0))) if len(images) else torch.Tensor(image).unsqueeze(dim=0)\n",
    "            labels = torch.cat((labels, torch.Tensor(label))) if len(labels) else torch.Tensor(label)\n",
    "        except: print(\"Different dimensions: \", image.size(), label.size(), \". Skipping image.\")\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio\n",
    "import os\n",
    "\n",
    "def save_for_ae(loader, model, threshold, dir):\n",
    "    count = 0\n",
    "    seg_path, gt_path = os.path.join(dir, 'measures/segmentations'), os.path.join(dir, 'labels')\n",
    "    if not os.path.exists(os.path.join(dir, 'measures')):  os.makedirs(seg_path)\n",
    "    if not os.path.exists(os.path.join(dir, 'labels')): os.makedirs(gt_path) \n",
    "    for i, batch in enumerate(loader):\n",
    "        w, h = batch['label'][0].size()[0], batch['label'][0].size()[1]\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output_image = model(batch[\"image\"].to(device))\n",
    "            output_image = torchio.ScalarImage(tensor=output_image.cpu().numpy())\n",
    "        \n",
    "        # check if  pixels are non zero\n",
    "        if torch.count_nonzero(batch['label'][0]).item() > threshold:\n",
    "            count +=1 \n",
    "            label_image = torchio.ScalarImage(tensor=batch['label'].cpu().numpy())\n",
    "            output_image.save(os.path.join(seg_path, f'patient_{i:03d}.nii.gz'))\n",
    "            label_image.save(os.path.join(gt_path, f'segmentation_{i:03d}.nii.gz'))\n",
    "    print(f\"Successfully saved {count} images to \", dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    patch_ds,\n",
    "    batch_size=1,\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "save_for_ae(loader, unet, .005, 'data/prostate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "img = nib.load('data/spleen/segmentations/segmentation_10.nii.gz').get_fdata()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FORE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
