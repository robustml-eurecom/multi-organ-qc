{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from utils.utilsAcdc import generate_patient_info, preprocess\n",
    "\n",
    "patient_info = generate_patient_info(\"data/heart/training/\", patient_ids=range(1, 101))\n",
    "patient_info = {**patient_info, **generate_patient_info(\"data/heart/testing/\", patient_ids=range(101, 151))}\n",
    "\n",
    "if not os.path.exists(\"preprocessed/heart\"):\n",
    "    os.makedirs(\"preprocessed/heart/\")\n",
    "np.save(os.path.join(\"preprocessed/heart/\", \"patient_info\"), patient_info)\n",
    "\n",
    "#spacings = [patient_info[id][\"spacing\"] for id in range(1, 101)]\n",
    "#spacing_target = np.percentile(np.vstack(spacings), 50, 0)\n",
    "spacing_target = [10, 1.25, 1.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"preprocessed/heart/training/\"):\n",
    "    os.makedirs(\"preprocessed/heart/training/\")\n",
    "preprocess(\n",
    "    range(1,101), patient_info, spacing_target,\n",
    "    \"data/heart/training\", \"preprocessed/heart/training\",\n",
    "    lambda folder, id: os.path.join(folder, 'patient{:03d}'.format(id)),\n",
    "    lambda patient_info, id, phase: \"patient{:03d}_frame{:02d}_gt.nii.gz\".format(id, patient_info[id][phase])\n",
    ")\n",
    "\n",
    "for model in os.listdir(\"data/heart/predictions/\"):\n",
    "    if not os.path.exists(\"preprocessed/heart/predictions/{}\".format(model)):\n",
    "        os.makedirs(\"preprocessed/heart/predictions/{}\".format(model))\n",
    "    preprocess(\n",
    "        range(101,151), patient_info, spacing_target,\n",
    "        \"data/heart/predictions/{}\".format(model), \"preprocessed/heart/predictions/{}\".format(model),\n",
    "        lambda folder, id: folder,\n",
    "        lambda patient_info, id, phase: \"patient{:03d}_{}.nii.gz\".format(id,phase)\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision\n",
    "from src.utils.utilsAcdc import AddPadding, CenterCrop, OneHot, ToTensor, MirrorTransform, SpatialTransform\n",
    "\n",
    "ids = random.sample(range(1, 101), 100)\n",
    "train_ids = ids[:80]\n",
    "val_ids = ids[80:]\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    AddPadding((256,256)),\n",
    "    CenterCrop((256,256)),\n",
    "    OneHot(),\n",
    "    ToTensor()\n",
    "])\n",
    "transform_augmentation = torchvision.transforms.Compose([\n",
    "    MirrorTransform(),\n",
    "    SpatialTransform(patch_size=(256,256), angle_x=(-np.pi/6,np.pi/6), scale=(0.7,1.4), random_crop=True),\n",
    "    OneHot(),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "#importlib.reload(sys.modules['src/ConvAE'])\n",
    "\n",
    "import torch\n",
    "from src.ConvAE.basic_model import AE\n",
    "from src.ConvAE.utils import hyperparameter_tuning, plot_history\n",
    "from src.utils.utilsAcdc import ACDCDataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#the following cell allows the user to tune his own hyperparameters. In case you wanna try our hyperparameters first, just skip this cell.\n",
    "\n",
    "#this is a list of possible values being tested for each hyperparameter.\n",
    "parameters = {\n",
    "    \"DA\": [True, False], #data augmentation\n",
    "    \"latent_size\": [100, 500], #size of the latent space of the autoencoder\n",
    "    \"BATCH_SIZE\": [8, 16, 4],\n",
    "    \"optimizer\": [torch.optim.Adam],\n",
    "    \"lr\": [2e-4, 1e-4, 1e-3],\n",
    "    \"weight_decay\": [1e-5],\n",
    "    \"tuning_epochs\": [5, 10], #number of epochs each configuration is run for\n",
    "    \"functions\": [[\"GDLoss\", \"MSELoss\"], [\"GDLoss\"], [\"BKGDLoss\", \"BKMSELoss\"]], #list of loss functions to be evaluated. BK stands for \"background\", which is a predominant and not compulsory class (it can lead to a dumb local minimum retrieving totally black images).\n",
    "    \"settling_epochs_BKGDLoss\": [10, 0], #during these epochs BK has half the weight of LV, RV and MYO in the evaluation of BKGDLoss\n",
    "    \"settling_epochs_BKMSELoss\": [10, 0], #during these epochs BK has half the weight of LV, RV and MYO in the evaluation of BKMSELoss\n",
    "}\n",
    "\n",
    "#this is a list of rules cutting out some useless combinations of hyperparameters from the tuning process.\n",
    "rules = [\n",
    "    '\"settling_epochs_BKGDLoss\" == 0 or \"BKGDLoss\" in \"functions\"',\n",
    "    '\"settling_epochs_BKMSELoss\" == 0 or \"BKMSELoss\" in \"functions\"',\n",
    "    '\"BKGDLoss\" not in \"functions\" or \"settling_epochs_BKGDLoss\" <= \"tuning_epochs\"',\n",
    "    '\"BKMSELoss\" not in \"functions\" or \"settling_epochs_BKMSELoss\" <= \"tuning_epochs\"',\n",
    "    #'\"BKGDLoss\" not in \"functions\" or \"settling_epochs_BKGDLoss\" >= \"settling_epochs_BKMSELoss\"'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_parameters = hyperparameter_tuning(\n",
    "    parameters,\n",
    "    ACDCDataLoader(\"preprocessed/heart/training\", patient_ids=train_ids, batch_size=None, transform=None),\n",
    "    ACDCDataLoader(\"preprocessed/heart/training\", patient_ids=val_ids, batch_size=None, transform=None),\n",
    "    transform, transform_augmentation,\n",
    "    rules,\n",
    "    fast=True) #very important parameter. When False, all combinations are tested to return the one retrieving the maximum DSC. When True, the first combination avoiding dumb local minima is returned.\n",
    "\n",
    "np.save(os.path.join(\"preprocessed/heart/\", \"optimal_parameters\"), optimal_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ConvAE.config import KEYS\n",
    "from src.ConvAE.loss import BKGDLoss, BKMSELoss, SSIMLoss \n",
    "\n",
    "upload_your_own_parameters = False\n",
    "\n",
    "if upload_your_own_parameters:\n",
    "    optimal_parameters = np.load(os.path.join(\"preprocessed/heart\", \"optimal_parameters.npy\"), allow_pickle=True).item()\n",
    "else:\n",
    "    optimal_parameters = {\n",
    "        \"BATCH_SIZE\": 8,\n",
    "        \"DA\": False,\n",
    "        \"in_channels\": 4,\n",
    "        \"out_channels\": 4,\n",
    "        \"latent_channels\": 100,\n",
    "        \"activation\": \"leaky_relu\",\n",
    "        \"optimizer\": torch.optim.Adam,\n",
    "        \"lr\": 2e-4,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"functions\": {\n",
    "            \"BKGDLoss\": BKGDLoss(), \n",
    "            \"BKMSELoss\": BKMSELoss()\n",
    "            },\n",
    "        \"settling_epochs_BKGDLoss\": 10,\n",
    "        \"settling_epochs_BKMSELoss\": 0\n",
    "        }\n",
    "    np.save(os.path.join(\"preprocessed/heart\", \"optimal_parameters\"), optimal_parameters)\n",
    "\n",
    "assert optimal_parameters is not None, \"Be sure to continue with a working set of hyperparameters\"\n",
    "\n",
    "BATCH_SIZE = optimal_parameters[\"BATCH_SIZE\"]\n",
    "DA = optimal_parameters[\"DA\"]\n",
    "\n",
    "ae = AE(**optimal_parameters, keys=KEYS).to(device)\n",
    "\n",
    "ckpt = None\n",
    "if ckpt is not None:\n",
    "    ckpt = torch.load(ckpt)\n",
    "    ae.load_state_dict(ckpt[\"AE\"])\n",
    "    ae.optimizer.load_state_dict(ckpt[\"AE_optim\"])\n",
    "    start = ckpt[\"epoch\"]+1\n",
    "else:\n",
    "    start = 0\n",
    "\n",
    "print(ae)\n",
    "\n",
    "plot_history(\n",
    "    ae.training_routine(\n",
    "        range(start, 50),\n",
    "        ACDCDataLoader(\"preprocessed/heart/training\", patient_ids=train_ids, batch_size=BATCH_SIZE, transform=transform_augmentation if DA else transform),\n",
    "        ACDCDataLoader(\"preprocessed/heart/training\", patient_ids=val_ids, batch_size=BATCH_SIZE, transform=transform),\n",
    "        \"checkpoints/\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import nibabel as nib\n",
    "from src.ConvAE.basic_model import AE\n",
    "from src.utils.utilsAcdc import testing, display_image, display_difference, process_results, display_plots, ACDCDataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimal_parameters = np.load(os.path.join(\"preprocessed/heart\", \"optimal_parameters.npy\"), allow_pickle=True).item()\n",
    "assert optimal_parameters is not None, \"Be sure to continue with a working set of hyperparameters\"\n",
    "\n",
    "ckpt = os.path.join(\"checkpoints\", sorted([file for file in os.listdir(\"checkpoints\") if \"_best\" in file])[-1])\n",
    "ckpt = torch.load(ckpt)\n",
    "\n",
    "ae = AE(**optimal_parameters, keys=KEYS).to(device)\n",
    "ae.load_state_dict(ckpt[\"AE\"])\n",
    "ae.optimizer.load_state_dict(ckpt[\"AE_optim\"])\n",
    "ae.eval();\n",
    "\n",
    "patient_info = np.load(\"preprocessed/heart/patient_info.npy\", allow_pickle=True).item()\n",
    "#spacings = [patient_info[id][\"spacing\"] for id in range(1, 101)]\n",
    "#current_spacing = np.percentile(np.vstack(spacings), 50, 0)\n",
    "current_spacing = [10, 1.25, 1.25]\n",
    "\n",
    "test_loaders = {}\n",
    "for model in os.listdir(\"preprocessed/heart/predictions/\"):\n",
    "    test_loaders[model] = ACDCDataLoader(\"preprocessed/heart/predictions/{}\".format(model), patient_ids=range(101, 151), batch_size=BATCH_SIZE, transform=transform)\n",
    "\n",
    "if not os.path.exists(\"postprocessed/heart/measures\"):\n",
    "    os.makedirs(\"postprocessed/heart/measures\")\n",
    "for model in sorted(test_loaders.keys()):\n",
    "    if not os.path.exists(\"postprocessed/heart/predictions/{}\".format(model)):\n",
    "        os.makedirs(\"postprocessed/heart/predictions/{}\".format(model))\n",
    "    results = testing(ae, test_loaders[model], patient_info, \"data/heart/predictions/{}\".format(model), \"postprocessed/heart/predictions/{}\".format(model), current_spacing)\n",
    "    np.save(\"postprocessed/heart/measures/{}_AE.npy\".format(model), results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Bai\"\n",
    "patient_id = np.random.choice(range(101, 151))\n",
    "phase = \"ED\"\n",
    "\n",
    "prediction = nib.load(\"data/heart/predictions/{}/patient{:03d}_{}.nii.gz\".format(model, patient_id, phase)).get_fdata().transpose(2, 1, 0)\n",
    "reconstruction = nib.load(\"postprocessed/heart/predictions/{}/patient{:03d}_{}.nii.gz\".format(model, patient_id, phase)).get_fdata().transpose(2, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utilsAcdc import display_image, display_difference\n",
    "display_image(prediction[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(reconstruction[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_difference(prediction[2], reconstruction[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FORE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
